# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
The dataset used for this experiment contained information about a marketing campaign from a banking network.  Information included age, marital status, default, loan information, and education.  The bank is looking to predict the probability of a successful engagement with a client.

The best performing model was a voting ensemble model generated using AutoML with an accuracy of 0.9174.

## Scikit-learn Pipeline
Initially, a standard logistic regression model was used to set a baseline expectation for model performance.  Data was normalized and cleaned before being put into the model architecture.  Then, the hyperparameters were tuned looking at regularization strength and the number of maxmimum iterations for the solvers to converge.  

Parameter sampling was executed using a random parameter sampler.  The random sampler doesn't require and exhaustive run through all hyperparameter options, therefore increasing the runtime of the program.

A Bandit policy for early stopping was used with the parameter sampler.  This tests how future runs compare to the best performing model after a specified number of intervals.  This allows runs to be stopped prematurely if they will not be in the competitive interval for best model.  Again, this improves the runtime of the program.

## AutoML
The model generated by using AutoML was a voting ensemble model.  The models used in this ensemble were: 'LightGBM', 'XGBoostClassifier', 'XGBoostClassifier', 'XGBoostClassifier', 'XGBoostClassifier', 'LogisticRegression', 'SGD'.

## Pipeline comparison
The AutoML pieline outperformed the hyperparameter tuning of the logistic regression with an accuracy of 0.9174 vs 0.9103.  However, with the steps that were taken to reduce the runtime of the logistic regression parameter search it executed in about half of the time as AutoML.  A reason for this could have also been the simplicity in executing a logistic regression compared to numerous different ensemble modeling efforts.

## Future work
In the future the logistic regression model could be improved by experimenting with even more of the hyperparameters for a logistic regression to find the most optimal model.  Additionally, more time and a more generous stopping criteria could be applied for both the logistic regression and AutoML if there was no boundry to compute size and time.

